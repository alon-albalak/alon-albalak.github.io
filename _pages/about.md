---
permalink: /
title: "About Me - Alon Albalak"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a fifth year Ph.D. candidate in the [NLP Group](http://nlp.cs.ucsb.edu/) at the University of California, Santa Barbara. I am gratefully advised by professors [William Yang Wang](https://sites.cs.ucsb.edu/~william/) and [Xifeng Yan](https://sites.cs.ucsb.edu/~xyan/). While pursuing my Ph.D. I took a year off from research to work at a financial technology startup, [Theta Lake](https://thetalake.com/). Prior to UCSB I received my B.S. in mathematics at [Wayne State University](https://clas.wayne.edu/math).

My research interests include a broad range of topics within machine learning and natural language processing.
However the *main focus* of my research is to find new methods of **efficiently using limited amounts of data**. In my path to improving data efficiency I have utilized:
1. Transfer learning ([1](https://arxiv.org/abs/2205.06262),[2](https://aclanthology.org/2022.nlp4convai-1.4/),[3](https://assets.amazon.science/80/f0/ad9a999f4562b6e80186a5df00e6/making-something-out-of-nothing-building-robust-task-oriented-dialogue-systems-from-scratch.pdf),[4](https://arxiv.org/abs/2210.03871)),
2. Data augmentation ([1](https://assets.amazon.science/80/f0/ad9a999f4562b6e80186a5df00e6/making-something-out-of-nothing-building-robust-task-oriented-dialogue-systems-from-scratch.pdf),[2](https://arxiv.org/abs/2201.11153)),
3. Neuro-symbolic methods ([1](https://arxiv.org/abs/2205.14268), [2](https://openreview.net/pdf?id=8ZIJa8Z__5L), [3](https://arxiv.org/abs/2207.07238)).

<hr>

## \*\* NEWS \*\*

### \[10/22\] My paper on benchmarking task transfer will be at EMNLP '22: [FETA](https://arxiv.org/abs/2205.06262)
FETA is the largest NLP benchmark for intra-dataset task transfer, where task transfer is isolated from domain shift.<br>
Check out the [paper](https://arxiv.org/abs/2205.06262), and our [github repo](https://github.com/alon-albalak/TLiDB).

### \[07/22\] I am organizing the Transfer Learning for NLP Workshop, co-located with NeurIPS 2022!
TL4NLP will explore insights and advances on characterizing positive and negative transfer.<br>
Check out the amazing lineup of speakers, topics, and more at [tl4nlp.githb.io](https://tl4nlp.github.io).

### \[05/22\] I will join Meta as a Research Science Intern for summer 2022!

### \[05/22\] The UCSB [GauchoBot](https://www.amazon.science/alexa-prize/teams/university-of-california-santa-barbara-team-gauchobot) has advanced to the finals of the Alexa Prize Taskbot Challenge!

### \[04/22\] [D-REX](https://aclanthology.org/2022.nlp4convai-1.4/) accepted to ConvAI workshop, co-located with ACL 2022
